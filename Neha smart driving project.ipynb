{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading facial landmark predictor...\n",
      "Enter the code for the Capturing device : 0\n",
      "[INFO] starting video stream thread...\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages SENSOR.py\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import playsound\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "def sound_alarm(path):\n",
    "    # play an alarm sound\n",
    "    playsound.playsound(path)\n",
    "\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    # return the eye aspect ratio\n",
    "    return ear\n",
    "# construct the argument parse and parse the arguments\n",
    "\n",
    "# define two constants, one for the eye aspect ratio to indicate\n",
    "# blink and then a second constant for the number of consecutive\n",
    "# frames the eye must be below the threshold for to set off the\n",
    "# alarm\n",
    "EYE_AR_THRESH = 0.3\n",
    "EYE_AR_CONSEC_FRAMES = 48\n",
    "\n",
    "# initialize the frame counter as well as a boolean used to\n",
    "# indicate if the alarm is going off\n",
    "COUNTER = 0\n",
    "ALARM_ON = False\n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "# grab the indexes of the facial landmarks for the left and\n",
    "# right eye, respectively\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "# start the video stream thread\n",
    "print(\"Enter the code for the Capturing device :\",end=\" \")\n",
    "kk=0\n",
    "kk=int(input())\n",
    "print(\"[INFO] starting video stream thread...\")\n",
    "vs = VideoStream(src=kk).start()\n",
    "time.sleep(1.0)\n",
    "p=\"tim.wav\"\n",
    "k=0\n",
    "# loop over frames from the video stream\n",
    "while True:\n",
    "    a=[]\n",
    "    k+=1\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #frame=cv2.imread(\"im.jpg\")\n",
    "    # detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)\n",
    "    #cv2.imshow(\"Frame\", frame)\n",
    "    # loop over the face detections\n",
    "    for rect in rects:\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        # extract the left and right eye coordinates, then use the\n",
    "        # coordinates to compute the eye aspect ratio for both eyes\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        # average the eye aspect ratio together for both eyes\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "        # compute the convex hull for the left and right eye, then\n",
    "        # visualize each of the eyes\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        # check to see if the eye aspect ratio is below the blink\n",
    "        # threshold, and if so, increment the blink frame counter\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER += 1\n",
    "            # if the eyes were closed for a sufficient number of\n",
    "            # then sound the alarm\n",
    "            if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                # if the alarm is not on, turn it on\n",
    "                if not ALARM_ON:\n",
    "                    ALARM_ON = True\n",
    "                    # check to see if an alarm file was supplied,\n",
    "                    # and if so, start a thread to have the alarm\n",
    "                    # sound played in the background\n",
    "                    if p != \"\":\n",
    "                        t = Thread(target=sound_alarm,args=(p,))\n",
    "                        t.deamon = True\n",
    "                        t.start()\n",
    "                    # draw an alarm on the frame\n",
    "                    cv2.putText(frame, \"DROWSINESS ALERT!\", (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        # otherwise, the eye aspect ratio is not below the blink\n",
    "        # threshold, so reset the counter and alarm\n",
    "        else:\n",
    "            COUNTER = 0\n",
    "            ALARM_ON = False\n",
    "            # draw the computed eye aspect ratio on the frame to help\n",
    "            # with debugging and setting the correct eye aspect ratio\n",
    "            # thresholds and frame counters\n",
    "            cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            # show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == 27:\n",
    "        break\n",
    "    # do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a9.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)  # set Width\n",
    "cap.set(4, 480)  # set Height\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)  # Flip camera vertically\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    # cv2.imshow('gray', gray)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:  # press 'ESC' to quit\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the folder to search for people: images\n",
      "Enter the person to check: N.jpeg\n",
      "im\n",
      "WARNING: No faces found in images\\kitty-cat.jpeg. Ignoring file.\n",
      "Lokesh\n",
      "WARNING: No faces found in images\\see.jpg. Ignoring file.\n",
      "im.jpg,im\n"
     ]
    }
   ],
   "source": [
    "# sensor2.py\n",
    "from __future__ import print_function\n",
    "import click\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import face_recognition\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import sys\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def scan_known_people(known_people_folder):\n",
    "    known_names = []\n",
    "    known_face_encodings = []\n",
    "\n",
    "    for file in image_files_in_folder(known_people_folder):\n",
    "        basename = os.path.splitext(os.path.basename(file))[0]\n",
    "        img = face_recognition.load_image_file(file)\n",
    "        encodings = face_recognition.face_encodings(img)\n",
    "\n",
    "        if len(encodings) > 1:\n",
    "            print(\"WARNING: More than one face found in {}. Only considering the first face.\".format(file))\n",
    "\n",
    "        if len(encodings) == 0:\n",
    "            print(\"WARNING: No faces found in {}. Ignoring file.\".format(file))\n",
    "        else:\n",
    "            known_names.append(basename)\n",
    "            print(basename)\n",
    "            known_face_encodings.append(encodings[0])\n",
    "\n",
    "    return known_names, known_face_encodings\n",
    "\n",
    "\n",
    "def print_result(filename, name, distance, show_distance=False):\n",
    "    if show_distance:\n",
    "        print(\"{},{},{}\".format(filename, name, distance))\n",
    "    else:\n",
    "        print(\"{},{}\".format(filename, name))\n",
    "\n",
    "\n",
    "def test_image(image_to_check, known_names, known_face_encodings, tolerance=0.6, show_distance=False):\n",
    "    unknown_image = face_recognition.load_image_file(image_to_check)\n",
    "\n",
    "    # Scale down image if it's giant so things run a little faster\n",
    "    if max(unknown_image.shape) > 1600:\n",
    "        pil_img = PIL.Image.fromarray(unknown_image)\n",
    "        pil_img.thumbnail((1600, 1600), PIL.Image.LANCZOS)\n",
    "        unknown_image = np.array(pil_img)\n",
    "\n",
    "    unknown_encodings = face_recognition.face_encodings(unknown_image)\n",
    "\n",
    "    for unknown_encoding in unknown_encodings:\n",
    "        distances = face_recognition.face_distance(known_face_encodings, unknown_encoding)\n",
    "        result = list(distances <= tolerance)\n",
    "\n",
    "        if True in result:\n",
    "            [print_result(image_to_check, name, distance, show_distance) for is_match, name, distance in zip(result, known_names, distances) if is_match]\n",
    "        else:\n",
    "            print_result(image_to_check, \"unknown_person\", None, show_distance)\n",
    "\n",
    "    if not unknown_encodings:\n",
    "        # print out fact that no faces were found in image\n",
    "        print_result(image_to_check, \"no_persons_found\", None, show_distance)\n",
    "\n",
    "\n",
    "def image_files_in_folder(folder):\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if re.match(r'.*\\.(jpg|jpeg|png)', f, flags=re.I)]\n",
    "\n",
    "\n",
    "def process_images_in_process_pool(images_to_check, known_names, known_face_encodings, number_of_cpus, tolerance, show_distance):\n",
    "    if number_of_cpus == -1:\n",
    "        processes = None\n",
    "    else:\n",
    "        processes = number_of_cpus\n",
    "\n",
    "    # macOS will crash due to a bug in libdispatch if you don't use 'forkserver'\n",
    "    context = multiprocessing\n",
    "    if \"forkserver\" in multiprocessing.get_all_start_methods():\n",
    "        context = multiprocessing.get_context(\"forkserver\")\n",
    "\n",
    "    pool = context.Pool(processes=processes)\n",
    "\n",
    "    function_parameters = zip(\n",
    "        images_to_check,\n",
    "        itertools.repeat(known_names),\n",
    "        itertools.repeat(known_face_encodings),\n",
    "        itertools.repeat(tolerance),\n",
    "        itertools.repeat(show_distance)\n",
    "    )\n",
    "\n",
    "    pool.starmap(test_image, function_parameters)\n",
    "\n",
    "\n",
    "\n",
    "def main(known_people_folder=\"images\", image_to_check=\"im.jpg\", cpus=1, tolerance=0.6, show_distance=False):\n",
    "    known_names, known_face_encodings = scan_known_people(known_people_folder)\n",
    "\n",
    "    # Multi-core processing only supported on Python 3.4 or greater\n",
    "    if (sys.version_info < (3, 4)) and cpus != 1:\n",
    "        click.echo(\"WARNING: Multi-processing support requires Python 3.4 or greater. Falling back to single-threaded processing!\")\n",
    "        cpus = 1\n",
    "\n",
    "    if os.path.isdir(image_to_check):\n",
    "        if cpus == 1:\n",
    "            [test_image(image_file, known_names, known_face_encodings, tolerance, show_distance) for image_file in image_files_in_folder(image_to_check)]\n",
    "        else:\n",
    "            process_images_in_process_pool(image_files_in_folder(image_to_check), known_names, known_face_encodings, cpus, tolerance, show_distance)\n",
    "    else:\n",
    "        test_image(image_to_check, known_names, known_face_encodings, tolerance, show_distance)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Enter the folder to search for people:\",end=\" \")\n",
    "    known_people_folder=input()\n",
    "    print(\"Enter the person to check:\",end=\" \")\n",
    "    image_to_check=input()\n",
    "    main(known_people_folder)\n",
    "    while True:\n",
    "        im=cv2.imread(image_to_check)\n",
    "        cv2.imshow(\"im\",im)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:  # press 'ESC' to quit\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
